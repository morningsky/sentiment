{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #导入Pandas\n",
    "import numpy as np #导入Numpy\n",
    "import jieba #导入结巴分词\n",
    "import thulac\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers import Bidirectional,Conv1D, GlobalMaxPooling1D,MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = pd.read_excel('./data/neg.xls', header=None, index=None)\n",
    "pos = pd.read_excel('./data/pos.xls', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos['mark'] = 1\n",
    "neg['mark'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn = pd.concat([pos, neg], ignore_index=True)#合并训练语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "neglen = len(neg)\n",
    "poslen = len(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded succeed\n"
     ]
    }
   ],
   "source": [
    "thu = thulac.thulac(seg_only=True)\n",
    "cw = lambda x:thu.cut(x, text=True).split() #定义分词函数\n",
    "pn['words'] = pn[0].apply(cw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = thu.cut('你离开了南京', text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['你', '离开', '了', '南京']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>mark</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持一...</td>\n",
       "      <td>1</td>\n",
       "      <td>[做, 父母, 一定, 要, 有, 刘墉, 这样, 的, 心态, ，, 不, 断, 地, 学...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...</td>\n",
       "      <td>1</td>\n",
       "      <td>[作者, 真, 有, 英国人, 严谨, 的, 风格, ，, 提出, 观点, 、, 进行, 论...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...</td>\n",
       "      <td>1</td>\n",
       "      <td>[作者, 长篇大论, 借用, 详细, 报告, 数据, 处理, 工作, 和, 计算, 结果, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...</td>\n",
       "      <td>1</td>\n",
       "      <td>[作者, 在, 战几, 时, 之前, 用, 了, ＂拥, 抱＂, 令, 人, 叫, 绝．, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...</td>\n",
       "      <td>1</td>\n",
       "      <td>[作者, 在, 少年, 时, 即, 喜, 阅读, ，, 能, 看出, 他, 精, 读, 了,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  mark  \\\n",
       "0  做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持一...     1   \n",
       "1  作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...     1   \n",
       "2  作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...     1   \n",
       "3  作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...     1   \n",
       "4  作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...     1   \n",
       "\n",
       "                                               words  \n",
       "0  [做, 父母, 一定, 要, 有, 刘墉, 这样, 的, 心态, ，, 不, 断, 地, 学...  \n",
       "1  [作者, 真, 有, 英国人, 严谨, 的, 风格, ，, 提出, 观点, 、, 进行, 论...  \n",
       "2  [作者, 长篇大论, 借用, 详细, 报告, 数据, 处理, 工作, 和, 计算, 结果, ...  \n",
       "3  [作者, 在, 战几, 时, 之前, 用, 了, ＂拥, 抱＂, 令, 人, 叫, 绝．, ...  \n",
       "4  [作者, 在, 少年, 时, 即, 喜, 阅读, ，, 能, 看出, 他, 精, 读, 了,...  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = pd.read_excel('./data/sum.xls')\n",
    "comment = comment[comment['rateContent'].notnull()] #仅读取非空评论\n",
    "comment['words'] = comment['rateContent'].apply(cw) #评论分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_train = pd.concat([pn['words'], comment['words']], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [] #将所有词典整合在一起\n",
    "for i in d2v_train:\n",
    "    w.extend(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1731397"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = pd.DataFrame(pd.Series(w).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>，</th>\n",
       "      <td>131885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>的</th>\n",
       "      <td>90355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>。</th>\n",
       "      <td>49352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>不</th>\n",
       "      <td>42181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>了</th>\n",
       "      <td>36955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>是</th>\n",
       "      <td>29478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>很</th>\n",
       "      <td>23337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>我</th>\n",
       "      <td>20122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>好</th>\n",
       "      <td>17632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>！</th>\n",
       "      <td>16576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>15644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>也</th>\n",
       "      <td>14239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>一</th>\n",
       "      <td>13285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>就</th>\n",
       "      <td>12115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>有</th>\n",
       "      <td>11961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>来</th>\n",
       "      <td>11946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>还</th>\n",
       "      <td>11220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>这</th>\n",
       "      <td>10972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>在</th>\n",
       "      <td>10901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>书</th>\n",
       "      <td>10338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>都</th>\n",
       "      <td>9340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>错</th>\n",
       "      <td>8662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>看</th>\n",
       "      <td>8536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>7638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>么</th>\n",
       "      <td>7567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>本</th>\n",
       "      <td>7441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>家</th>\n",
       "      <td>7183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>到</th>\n",
       "      <td>7128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>没有</th>\n",
       "      <td>7095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>买</th>\n",
       "      <td>6976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>健步</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>立意</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>工好</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>干凈</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>鲍鱼</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>过路车</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sync</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>子高高</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>星期充</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>金门路</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>诱惑力</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>选台</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>电识</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>上个把</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BC6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>小若09年</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>觉用</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HP外观</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>合弦版</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>铁口</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hp2205</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>⊿Τ</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>海瓜子</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>当车</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>送卡</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>信用商</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.进</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>提后</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>跳帧</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46915 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "，       131885\n",
       "的        90355\n",
       "。        49352\n",
       "不        42181\n",
       "了        36955\n",
       "是        29478\n",
       "很        23337\n",
       "我        20122\n",
       "好        17632\n",
       "！        16576\n",
       ",        15644\n",
       "也        14239\n",
       "一        13285\n",
       "就        12115\n",
       "有        11961\n",
       "来        11946\n",
       "还        11220\n",
       "这        10972\n",
       "在        10901\n",
       "书        10338\n",
       "都         9340\n",
       "错         8662\n",
       "看         8536\n",
       ".         7638\n",
       "么         7567\n",
       "本         7441\n",
       "家         7183\n",
       "到         7128\n",
       "没有        7095\n",
       "买         6976\n",
       "...        ...\n",
       "健步           1\n",
       "立意           1\n",
       "工好           1\n",
       "干凈           1\n",
       "鲍鱼           1\n",
       "过路车          1\n",
       "Sync         1\n",
       "子高高          1\n",
       "星期充          1\n",
       "金门路          1\n",
       "诱惑力          1\n",
       "选台           1\n",
       "电识           1\n",
       "上个把          1\n",
       "BC6          1\n",
       "小若09年        1\n",
       "觉用           1\n",
       "HP外观         1\n",
       "合弦版          1\n",
       "铁口           1\n",
       "hp2205       1\n",
       "⊿Τ           1\n",
       "海瓜子          1\n",
       "当车           1\n",
       "送卡           1\n",
       "信用商          1\n",
       ".进           1\n",
       "708          1\n",
       "提后           1\n",
       "跳帧           1\n",
       "\n",
       "[46915 rows x 1 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "del w,d2v_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict['id'] = list(range(1,len(dict)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sent = lambda x:list(dict['id'][x])\n",
    "pn['sent'] = pn['words'].apply(get_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>mark</th>\n",
       "      <th>words</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持一...</td>\n",
       "      <td>1</td>\n",
       "      <td>[做, 父母, 一定, 要, 有, 刘墉, 这样, 的, 心态, ，, 不, 断, 地, 学...</td>\n",
       "      <td>[151, 557, 297, 36, 15, 12113, 127, 2, 1727, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...</td>\n",
       "      <td>1</td>\n",
       "      <td>[作者, 真, 有, 英国人, 严谨, 的, 风格, ，, 提出, 观点, 、, 进行, 论...</td>\n",
       "      <td>[173, 93, 15, 22250, 2684, 2, 846, 1, 757, 758...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...</td>\n",
       "      <td>1</td>\n",
       "      <td>[作者, 长篇大论, 借用, 详细, 报告, 数据, 处理, 工作, 和, 计算, 结果, ...</td>\n",
       "      <td>[173, 6753, 5000, 1022, 4576, 1456, 667, 331, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...</td>\n",
       "      <td>1</td>\n",
       "      <td>[作者, 在, 战几, 时, 之前, 用, 了, ＂拥, 抱＂, 令, 人, 叫, 绝．, ...</td>\n",
       "      <td>[173, 19, 20012, 101, 436, 31, 5, 22818, 21451...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...</td>\n",
       "      <td>1</td>\n",
       "      <td>[作者, 在, 少年, 时, 即, 喜, 阅读, ，, 能, 看出, 他, 精, 读, 了,...</td>\n",
       "      <td>[173, 19, 2790, 101, 1453, 2100, 325, 1, 44, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  mark  \\\n",
       "0  做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持一...     1   \n",
       "1  作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...     1   \n",
       "2  作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...     1   \n",
       "3  作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...     1   \n",
       "4  作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...     1   \n",
       "\n",
       "                                               words  \\\n",
       "0  [做, 父母, 一定, 要, 有, 刘墉, 这样, 的, 心态, ，, 不, 断, 地, 学...   \n",
       "1  [作者, 真, 有, 英国人, 严谨, 的, 风格, ，, 提出, 观点, 、, 进行, 论...   \n",
       "2  [作者, 长篇大论, 借用, 详细, 报告, 数据, 处理, 工作, 和, 计算, 结果, ...   \n",
       "3  [作者, 在, 战几, 时, 之前, 用, 了, ＂拥, 抱＂, 令, 人, 叫, 绝．, ...   \n",
       "4  [作者, 在, 少年, 时, 即, 喜, 阅读, ，, 能, 看出, 他, 精, 读, 了,...   \n",
       "\n",
       "                                                sent  \n",
       "0  [151, 557, 297, 36, 15, 12113, 127, 2, 1727, 1...  \n",
       "1  [173, 93, 15, 22250, 2684, 2, 846, 1, 757, 758...  \n",
       "2  [173, 6753, 5000, 1022, 4576, 1456, 667, 331, ...  \n",
       "3  [173, 19, 20012, 101, 436, 31, 5, 22818, 21451...  \n",
       "4  [173, 19, 2790, 101, 1453, 2100, 325, 1, 44, 1...  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict['id']['做']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 50 #每一句话设置成50个词 不够的用空格填补 超出的截取 默认取后50个词 前面的补全\n",
    "pn['sent'] = list(sequence.pad_sequences(pn['sent'], maxlen=maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,   173,  2038,  3717,     1,\n",
       "        6459,     3,    29,    13,   517,  2215,     1,  5095,     1,\n",
       "       23435,     1, 21834,     3,    59,  5266,    92,   165,  5703,\n",
       "       22757,    14,  3305,     2,     8,   414, 18672,     1, 19808,\n",
       "         222,   714,     3,  5226,  9379,     1, 19484,     2,  3828,\n",
       "         556,     1,   177,   594,    10])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn['sent'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(list(pn['sent']))[::2]\n",
    "y_train = np.array(list(pn['mark']))[::2]\n",
    "x_test = np.array(list(pn['sent']))[1::2]\n",
    "y_test = np.array(list(pn['mark']))[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10553/10553 [==============================] - 82s 8ms/step - loss: 0.4487 - acc: 0.7900\n",
      "Epoch 2/10\n",
      "10553/10553 [==============================] - 80s 8ms/step - loss: 0.2062 - acc: 0.9263\n",
      "Epoch 3/10\n",
      "10553/10553 [==============================] - 81s 8ms/step - loss: 0.1095 - acc: 0.9633\n",
      "Epoch 4/10\n",
      "10553/10553 [==============================] - 82s 8ms/step - loss: 0.0554 - acc: 0.9820\n",
      "Epoch 5/10\n",
      "10553/10553 [==============================] - 80s 8ms/step - loss: 0.0397 - acc: 0.9875\n",
      "Epoch 6/10\n",
      "10553/10553 [==============================] - 81s 8ms/step - loss: 0.0261 - acc: 0.9919\n",
      "Epoch 7/10\n",
      "10553/10553 [==============================] - 80s 8ms/step - loss: 0.0244 - acc: 0.9926\n",
      "Epoch 8/10\n",
      "10553/10553 [==============================] - 79s 8ms/step - loss: 0.0199 - acc: 0.9939\n",
      "Epoch 9/10\n",
      "10553/10553 [==============================] - 80s 8ms/step - loss: 0.0143 - acc: 0.9958\n",
      "Epoch 10/10\n",
      "10553/10553 [==============================] - 80s 8ms/step - loss: 0.0219 - acc: 0.9934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26275128c88>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(dict)+1, 256))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.fit(x_train, y_train, batch_size=32, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10552/10552 [==============================] - 6s 566us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7284938269807039, 0.8610689916603488]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 10553 samples, validate on 10552 samples\n",
      "Epoch 1/5\n",
      "10553/10553 [==============================] - 78s 7ms/step - loss: 0.4515 - acc: 0.7887 - val_loss: 0.3397 - val_acc: 0.8623\n",
      "Epoch 2/5\n",
      "10553/10553 [==============================] - 78s 7ms/step - loss: 0.2107 - acc: 0.9254 - val_loss: 0.3751 - val_acc: 0.8684\n",
      "Epoch 3/5\n",
      "10553/10553 [==============================] - 78s 7ms/step - loss: 0.1115 - acc: 0.9652 - val_loss: 0.3952 - val_acc: 0.8658\n",
      "Epoch 4/5\n",
      "10553/10553 [==============================] - 78s 7ms/step - loss: 0.0680 - acc: 0.9790 - val_loss: 0.4608 - val_acc: 0.8692\n",
      "Epoch 5/5\n",
      "10553/10553 [==============================] - 79s 7ms/step - loss: 0.0408 - acc: 0.9858 - val_loss: 0.5951 - val_acc: 0.8507\n",
      "10552/10552 [==============================] - 3s 281us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5951174657612331, 0.8507391963608795]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(dict)+1, 128))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=16,\n",
    "          epochs=5,\n",
    "          validation_data=[x_test, y_test])\n",
    "model.evaluate(x_test, y_test, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(dict)+1,\n",
    "                    128,input_length=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(250,\n",
    "                 3,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "# we use max pooling:\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(250))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=16,\n",
    "          epochs=5,\n",
    "          validation_data=(x_test, y_test))\n",
    "model.evaluate(x_test, y_test, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CMM + LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(dict)+1, 128))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(64,\n",
    "                 5,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(LSTM(70))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=16,\n",
    "          epochs=5,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=16)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(s,model):\n",
    "    s = list(jieba.cut(s))\n",
    "    s_vec = []\n",
    "    for i in s:\n",
    "        try:\n",
    "            s_vec.append(dict['id'][i])\n",
    "        except:\n",
    "            s_vec.append(0)\n",
    "    s_vec = np.array(s_vec)\n",
    "    s_vec = s_vec.reshape((1, s_vec.shape[0]))\n",
    "    s_vec = list(sequence.pad_sequences(s_vec, maxlen=maxlen))\n",
    "    s_vec = np.array(s_vec)\n",
    "    return model.predict_classes(s_vec, verbose=0)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '院线看电影这么多年以来，这是我第一次看电影睡着了。简直是史上最大烂片！没有之一！侮辱智商！大家小心警惕！千万不要上当！再也不要看了！'\n",
    "predict_one(s, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '你今天真好看'\n",
    "predict_one(s, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '我不是蒙牛，没你想象的那么纯'\n",
    "predict_one(s, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '打工肯定是不可能打工的，这辈子都不可能打工的，生活这么艰难，就只有偷这种东西才能维持得了生活这样子'\n",
    "predict_one(s, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '我不得不承认这台电脑真漂亮'\n",
    "predict_one(s, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '我不得不承认,这台电脑不仅是最漂亮的，还是最贵的'\n",
    "predict_one(s, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '我不承认,这台电脑不仅是最漂亮的，还是最贵的'\n",
    "predict_one(s, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '我之前说的你是个好人这句话是错的'\n",
    "predict_one(s, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
